<!DOCTYPE html>
<html>
<head>

  <meta charset="UTF-8">
  <title>Tutorial 3</title>
  <meta name="viewport" content="width=device-width">

  <!--[if lt IE 9]>
    <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->

  <!-- <link rel="stylesheet" href="//netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css"> -->
  <link href="/courses/BigData/assets/css/style.css" rel="stylesheet" />
  <link href="/courses/BigData/assets/css/colors.css" rel="stylesheet" />
  <link href="/courses/BigData/assets/css/pygments_style.css" rel="stylesheet" />
  <link href="/courses/BigData/assets/css/font-awesome.min.css" rel="stylesheet" />

  <script type="text/javascript" src="//code.jquery.com/jquery-1.10.2.min.js"></script>
  <script type="text/javascript" src="/courses/BigData/assets/js/jquery.qrcode.min.js"></script>

  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  tex2jax: {
  inlineMath: [['$','$']],
  processEscapes: true
  }
  });
  </script>
  <script type="text/javascript"
  src="https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  <script type="text/javascript" src="/courses/BigData/assets/js/jq_mathjax_parse.js"></script>

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

<!--<style>html{background: url(/courses/BigData/assets/img/background.png) no-repeat center center fixed;-webkit-background-size: cover;-moz-background-size: cover;-o-background-size: cover;background-size: cover;}</style>-->

</head>

<!--<body style="background-image:url('/courses/BigData/assets/img/background.png');">-->



<body>

  <header id="header" >
    <h1>
        
        <br>
        Big Data Analytics
    </h1>
    <h4>(Offered in 2018 Fall)</h4>
    <hr>
  </header>


  <div id="page">

    <div id="sidebar">
      <nav>
        <ul>
          <li><a href="/courses/BigData/"><i class="fa fa-home fa-fw"></i> Home</a></li>
          <!-- <li><a href="/courses/BigData/"><i class="fa fa-bullhorn fa-fw"></i> News</a></li> -->
          <li><a href="/courses/BigData/lecture/"><i class="fa fa-book fa-fw"></i> Lecture</a></li>
          <li><a href="/courses/BigData/tutorial/"><i class="fa fa-book fa-fw"></i> Tutorial</a></li>
		  <li><a href="/courses/BigData/project/"><i class="fa fa-book fa-fw"></i> Project</a></li>
          <li><a href="/courses/BigData/homework"><i class="fa fa-pencil fa-fw"></i> Homework</a></li>
          <li><a href="/courses/BigData/reference"><i class="fa fa-tag fa-fw"></i> Reference</a></li>
        </ul>
      </nav>
    </div>
    
    <div id="main">
    <div id="content">
      <h1>~ Tutorial 3 ~
      </h1>
      <div>
        <p id="feed" style="display:block; text-align:right">
          <a href="/courses/BigData/feed.xml"><i class="fa fa-rss fa-fw"></i>Feed</a>
        </p>
      </div>
      <br>
      <div>
        <article class="tutorial">

	<div class="tutorial-content"><h1>Hadoop Streaming</h1>

<h2>What is Hadoop Streaming?</h2>

<p>Hadoop streaming is a utility that comes with the Hadoop distribution. This utility allows you to create and run Map/Reduce jobs with any executable or script as the mapper and/or the reducer.</p>

<ul>
<li>Mapper and Reducer are just normal Linux executables.</li>
<li>Mapper: 
takes input stream from <a href="http://en.wikipedia.org/wiki/Standard_streams">standard input</a>;
emmit key-value pairs to <a href="http://en.wikipedia.org/wiki/Standard_streams">standard output</a>.
Each key-value pair takes one line and is formatted as <code>&#39;%s\t%s&#39; % (key, value)</code>.</li>
<li>Reducer:
takes input key-value pairs from STDIN; output key-value pairs to STDOUT.</li>
<li>By default, key and value are seperated by tab. If there is no tab (&#39;\t&#39;), the whole line is treated as a key and the value is null.</li>
</ul>

<h2>Run with Hadoop Streaming</h2>

<p>The command format is as follows:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>hduser@master:~$ hadoop jar hadoop-streaming-2.7.1.jar \
    -input myInputDirs \
    -output myOutputDir \
    -mapper java_class_or_executable \
    -reducer java_class_or_executable
</code></pre></div>
<p>If you are running Hadoop in DIC cluster, you can find <code>hadoop-streaming.jar</code> under <code>/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar</code>.</p>

<ul>
<li><code>-input directoryname or filename</code>: Input location in the HDFS for mapper. Required.</li>
<li><code>-output directoryname</code>: Output location in the HDFS for reducer. Required.</li>
<li><code>-mapper executable or JavaClassName</code>: Mapper executable in the local file system. Required.</li>
<li><code>-reducer executable or JavaClassName</code>: Reducer executable in the local file system.</li>
</ul>

<p>This time, instead of running word count with <code>hadoop-mapreduce-examples.jar</code>(under <code>/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar</code>), we are going to write the mapper and recuder, and run it with <code>hadoop-streaming.jar</code>.</p>

<p>In this tutorial we will use Python. Fisrt of all, we design our mapper as (<code>mapper.py</code>):</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>#!/usr/bin/env python

import sys

for line in sys.stdin:
    for word in line.split():
        print &#39;%s\t%s&#39; % (word, 1)
</code></pre></div>
<p>Write the reducer as (<code>reducer.py</code>):</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>#!/usr/bin/env python

import sys

cur_key = None
cur_count = 0

for line in sys.stdin:
    key, value = line.split()

    #Accumulate count for a word
    if key == cur_key:
        cur_count += int(value)
    else:
        #finish counting for a certain word
        if cur_key:
            print &#39;%s\t%s&#39; % (cur_key, cur_count)
        cur_key = key
        cur_count = int(value)

#Output the last word
print &#39;%s\t%s&#39; % (cur_key, cur_count)
</code></pre></div>
<p>Run it with Hadoop Streaming:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>hduser@master:~$ hadoop jar hadoop-streaming-2.7.1.jar -file mapper.py -mapper mapper.py -file reducer.py -reducer reducer.py -input /largefile -output /result
</code></pre></div>
<h2>The most frequent words</h2>

<p>Following up the previous word count example, how can we get the most frequent words using MapReduce? Check the reducer output in the previous job. </p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>hduser@master:~$ hadoop dfs -cat /result/part-00000 | head -n 5
</code></pre></div>
<h3>Option 1</h3>

<p>We know Hadoop will sort the intermediate results by the key. Let&#39;s leverage this property and design our mapper as (<code>swap.py</code>):</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>#!/usr/bin/env python

import sys

for line in sys.stdin:
    word, count = line.split()
    print &#39;%07d\t%s&#39; % (int(count), word)
</code></pre></div>
<p>Notes: By default, shuffling stage performs a string sorting, not integer sorting. We played a trick, <code>%07d</code>, to pad leading zeros, so that string sorting and integer sorting are equivalent in this case.</p>

<p>We don&#39;t need a reducer in this case. Run with Hadoop Streaming:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>hduser@master:~$ hadoop jar hadoop-streaming-2.7.1.jar -mapper swap.py -file swap.py -input /result -output /result_sorted
</code></pre></div>
<p>Check the output:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>hduser@master:~$ hadoop dfs -cat /result_sorted/part-00000 | tail -n 5
</code></pre></div>
<p><strong>Caution</strong>: <code>hadoop dfs -cat</code> can cause a lot network traffic in practice if you have a really large data set. Don&#39;t use <code>-cat</code> in real works and homeworks (just add a reducer if necessary).</p>

<h3>Option 2</h3>

<p>There are many parameters you can specify in the command line argument. Try the following command:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>hduser@master:~$ hadoop jar hadoop-streaming-2.7.1.jar \
    -D stream.num.map.output.key.fields=2 \
    -D mapred.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator \
    -D mapred.text.key.comparator.options=-k2,2nr \
    -mapper cat -reducer cat -input /result -output /result_sorted2 \
</code></pre></div>
<ul>
<li><code>-D property=value</code>: Use value for given property </li>
<li><code>-D stream.num.map.output.key.fields</code>: Specify how many fields as the key</li>
<li><code>-D mapred.output.key.comparator.class</code>: Use the library class, KeyFieldBasedComparator, as the comparator, allowing the Map/Reduce framework to compare the map outputs based on certain key fields, not the whole keys.</li>
<li><code>-D mapred.text.key.comparator.options</code>: Specify the comparator rule -- <code>-k2,2</code> means sort the second field; <code>n</code> means in numerical order; <code>r</code> means reverse.</li>
</ul>

<h2>Other useful streaming command options</h2>

<ul>
<li><code>-partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner</code>: Use the library class, KeyFieldBasedPartitioner, as the Partitioner, allowing the Map/Reduce framework to partition the map outputs based on certain key fields, not the whole keys. (What&#39;s the difference between partition and comparator?)</li>
<li><code>-D mapred.text.key.partitioner.options</code>: Specify the rule to partition the intermediate tuples.</li>
<li><code>-D stream.map.output.field.separator</code>: Specify your own separator between key and value.</li>
<li><code>-D mapred.reduce.tasks</code>: Specify the number of reducers.</li>
<li><code>-D mapred.map.tasks</code>: A hint to the number of mappers. If not work, you may want to change mapred.min.split.size in mapred-site.xml.</li>
</ul>

<h1>Secondary Sort</h1>

<h2>What is Secondary Sort?</h2>

<ul>
<li><a href="SecondSort.ppt">Secondary Sort/Composite Key</a></li>
</ul>

<h2>Reference</h2>

<ul>
<li>Hadoop Streaming:<a href="https://hadoop.apache.org/docs/r1.2.1/streaming.html">https://hadoop.apache.org/docs/r1.2.1/streaming.html</a></li>
<li>Python Tutoail: <a href="https://docs.python.org/2/tutorial/">https://docs.python.org/2/tutorial/</a></li>
<li>Java Word Count Example: <a href="https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html</a></li>
<li>Secondary Sort Example: <a href="http://dl.farinsoft.ir/files/94/Data-Algorithms-Recipes-Scaling-Hadoop.pdf">http://dl.farinsoft.ir/files/94/Data-Algorithms-Recipes-Scaling-Hadoop.pdf</a></li>
<li>DIC user guide: <a href="http://mobitec.ie.cuhk.edu.hk/engg4030Fall2016/homework/AguidetouseIEDICcluster.pdf">http://mobitec.ie.cuhk.edu.hk/engg4030Fall2016/homework/AguidetouseIEDICcluster.pdf</a></li>
</ul>
</div>

</article>

<footer>

<hr>

Bookmark this tutorial:

<div id="qrcode"></div>

<hr>

<small>
<a rel="license" href="http://creativecommons.org/licenses/by/4.0/">
<img alt="Creative Commons License" style="display:inline;margin:0;width:88px;height:31px;border-width:0" src="http://i.creativecommons.org/l/by/4.0/88x31.png" />
</a>
This work is licensed under a
<a rel="license" href="http://creativecommons.org/licenses/by/4.0/">
Creative Commons Attribution 4.0 International License</a>.
</small>

      </div>
    </div>
    </div>

  


  <footer id="footer">
    <p class="copyright">Copyright &copy; 2018 Dongguan University-. Powered by <a href="http://jekyllrb.com">Jekyll</a>, original theme by <a href="http://www.webmaster-source.com">Matt Harzewski</a>,
      modified by <a href="https://home.ie.cuhk.edu.hk/~hlxu">Huanle Xu</a>
    </p>
    <p>
      <small>Site last compiled at: 2018-10-16 14:05:42 +0800</small>
    </p>
  </footer>

<script>
	//jQuery('#qrcode').qrcode("this plugin is great");
	jQuery('#qrcode').qrcode({
		//render	: "table",
		text	: $(location).attr('href'),
    width: 128,
    height: 128
	});
</script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-46660865-1', 'cuhk.edu.hk');
  ga('send', 'pageview');

</script>

</body>
</html>
